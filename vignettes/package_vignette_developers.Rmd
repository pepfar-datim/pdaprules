---
title: "Using pdarules for Developers"
author: "Vignette Author"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Setting up your Environment

In order to make sure you are setup to use rstudio properly, we recommend using a project directory. You can go to File > New Project > and either clone a directory or start a new project. If you choose a new directory you should see an option to check a box `use renv`. This will ensure that the `renv` package is installed and set up.

If you choose a different route or are not sure if `renv` is installed simply run `install.packages('renv')`, then run `renv::activate()`. This will create a `renv.lock` file that keeps track of your packages and also an `.rprofile` which holds any environment variables. `renv` is incredibly useful and will allow you to take snapshots of your installed packages making sure your work is sustainable and reproducible. Please review the documentation on `renv` if you need more help getting started: https://rstudio.github.io/renv/articles/renv.html#getting-started.

When R initiates certain environment variables will be available by default, specifically your aws credentials (added by our systems engineering team by default). In order to validate that you have access to your credential and bucket environment variables run the code block below:

```{r, echo = TRUE, eval = FALSE}
Sys.getenv("S3_READ")
Sys.getenv("S3_WRITE")
Sys.getenv("AWS_ACCESS_KEY_ID")
Sys.getenv("AWS_SECRET_ACCESS_KEY")
Sys.getenv("AWS_REGION")
```

Note these credentials ^ are secret and should never be shared with anyone.

## Accessing Raw Data in S3

Make sure the following libraries are installed and then declared for connecting to S3: 

```{r, echo = TRUE, eval = TRUE}
# install.packages("readr")
# install.packages("aws.s3")
# install.packages('devtools')
# devtools::install_github(repo = "https://github.com/pepfar-datim/pdaprules.git", ref = "main")
library(aws.s3)
library(pdaprules)
library(readr)
```

Once you have set up and validated your environment, you can now access data stored the S3_READ bucket which holds raw data (msd, financial data sets, narratives). Use the following code to connect to S3_READ and test reading a file: 

```{r, echo = TRUE, eval=TRUE}

my_items <- s3_list_bucket_items(bucket = Sys.getenv("S3_READ"))

# print out the first five items
print(my_items[1:5,])


#Filter those bucket items down
my_filtered_items <- s3_filter_PAW(bucketlist = my_items,
                                   category = "MER",
                                   subcategory = "Site_Recent",
                                   metadata = FALSE,
                                   country = c("Angola","Lesotho"))

#Read the the file or files
my_data <- s3_read_PAW(bucket = Sys.getenv("S3_READ"), path = my_filtered_items)

print(head(my_data))
```


## Writing and Sharing Data with S3: Read, Write, Delete

In the case that you wish to write your own dataset or share a report, every developer has write access to an S3 bucket known as S3_WRITE. Developers will have rights to a specific folder or "prefix" in this bucket where they can dump files.

You should be able to run the following code below to write, read or delete files (note depending on your access you will have to change the `my_prefix` variable to `pet` or `bao`):  


```{r, echo=TRUE, eval = FALSE}

my_prefix = 'bao/'
# my_prefix = 'pet/'

# write a test file
s3write_using(mtcars, FUN = write.csv,
             bucket = Sys.getenv("S3_WRITE"),
             object = paste0(my_prefix, "test.csv")
)

# read a file
s3read_using(FUN = read.csv,
             bucket = Sys.getenv("S3_WRITE"),
             object = paste0(my_prefix, "test.csv")
)

# delete the test file 
delete_object(
  bucket = Sys.getenv("S3_WRITE"),
  object = paste0(my_prefix, "S3_WRITE")
)

```
